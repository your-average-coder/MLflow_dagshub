{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/your-average-coder/MLflow_dagshub/blob/main/MLFlow_Experiment_Tracking_Workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><h1> üëã  Welcome to the Community MLFlow Crash Course by DagsHub!</h1>\n",
        "\n",
        "---\n",
        "\n",
        "<a><img src=\"https://i.imgur.com/95OyUss.jpg\" alt=\"Email-3\" border=\"0\"></a></center>\n",
        "\n",
        "With 243M downloads and 14.8K stars on GitHub - MLflow is one of the most widely adopted open-source tools for machine learning lifecycle management. It supports live logging of parameters, metrics, and artifacts, in addition to providing a Model Registry with Deployment functionality.\n",
        "\n",
        "We integrated MLflow into DagsHub almost two years ago, providing a zero-configuration remote MLflow Server with built-in access controls, that support MLflow's Tracking, Model Registry, and Deployment functionality. We've dived into its internals, handled many of its specifics, and now we want to share the knowledge we gained with the data science community!\n",
        "\n",
        "\n",
        "1. **Intro to MLflow**¬†- Learn what MLflow is and how it can help you manage your machine learning project.\n",
        "2. **Experiment Tracking**¬†live logging of parameters, metrics, and artifacts as part of machine learning experiments.\n",
        "3. **Model Registry**¬†- Log and manage your machine learning models with MLflow.\n",
        "2. **Model Deployment** -¬†Deploy your trained model from the MLflow registry to AWS.\n",
        "\n",
        "\n",
        "---\n",
        "<h4>\n",
        " In the session today, we will use DagsHub integration with MLflow. ‚ù§Ô∏è\n",
        "\n",
        " You will log experiment to a remote server by running only 3 simple commands!\n",
        "\n",
        " For that, you will need to sign up for DagsHub (for free) üëá\n",
        "</h4>\n",
        "<center><h3><a href=\"https://bit.ly/3Sjl9UA\">Sign up to DagsHub</a></h3></center>\n",
        "\n",
        "<center><img src=\"https://res-2.cloudinary.com/crunchbase-production/image/upload/c_lpad,f_auto,q_auto:eco/plwmuai9t3okgwbuhkho\" height=\"100\"/></center>\n",
        "\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "\n",
        "<img src=\"https://dragonballz.co.il/wp-content/uploads/2020/12/discord-logo.jpg\" height=\"23\"/> [Discord Channel](https://discord.com/channels/698874030052212737/698874030572437526) | <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c9/Linkedin.svg/1200px-Linkedin.svg.png\" height=\"23\"/> [LinkedIn](https://www.linkedin.com/company/dagshub/) | <img src=\"https://help.twitter.com/content/dam/help-twitter/brand/logo.png\" height=\"25\"/> [Twitter](https://twitter.com/TheRealDAGsHub) | <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Octicons-mark-github.svg/1200px-Octicons-mark-github.svg.png\" height=\"25\"/> [GitHub](https://github.com/DAGsHub) | <img src=\"\thttps://www.mlflow.org/docs/latest/_static/MLflow-logo-final-black.png\" height=\"30\"/> [MLFlow](https://www.mlflow.org/)\n",
        "\n"
      ],
      "metadata": {
        "id": "iWUkRt7z2hkK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚ùì What are we learning today?"
      ],
      "metadata": {
        "id": "i5AX2fpblSyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Why do we need MLflow?\n",
        "- What is MLflow?\n",
        "- MLflow Tracking Functionality\n",
        "  - Understanding Runs & Experiments\n",
        "  - Logging Runs & Experiments\n",
        "  - How and where are the runs recorded?\n",
        "- Hands-on Experience using MLflow"
      ],
      "metadata": {
        "id": "lG6_hUNcE4qy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ü§å Why do we need MLFlow?\n",
        "\n",
        "<p float=\"left\">\n",
        "  <img src=\"https://drive.google.com/uc?id=1ZMVUUsVDRaGRD_aIa8E-4lkGFxxo1WGB\" height=\"200\" />\n",
        "  <img src=\"https://drive.google.com/uc?id=1tK9igz88eMHV115R_0jDuzuPBY9GSTRQ\" height=\"220\" />\n",
        "  <img src=\"https://drive.google.com/uc?id=11QSKrW29sWfD2lPse_hXpYD9Ql6tLQjo\" height=\"200\" />\n",
        "</p>"
      ],
      "metadata": {
        "id": "w5e-om3x4qeA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**<h3>üí°The effort and time spent in logging the experiments is always underestimated</h3>**\n",
        "\n",
        "Do you find yourself doing CTRL-Y / ‚áß‚åòZ multiple times to find that perfect code which gave you an awesome accuracy or confidence score before you messed it up with the new experiment you decided to run? Or the optimal set of hyper parameters that you used for that run?\n",
        "\n",
        "**<h3>‚ùìAnother question that arises is of reproducibility of your experiments.</h3>**\n",
        "\n",
        "A colleague of mine structured their experiments using a Notion Table to keep track of them :\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1xD1aR3-yZICt9vMIdIHkATBMBAS6Pcbx\" height=\"\"/>\n",
        "</center>\n",
        "\n",
        "\n",
        "While Notion is a great tool for note keeping, we can‚Äôt say the same when it comes to tracking the machine learning experimentation and workflow."
      ],
      "metadata": {
        "id": "dtInWfJ_zZ0B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚ö° What is MLFlow?"
      ],
      "metadata": {
        "id": "IyObzxJLjGJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "MLflow is an **open-source tool** to manage the machine learning lifecycle. It supports **live logging** of parameters, metrics, metadata, and artifacts when running a machine learning experiment. To manage the post-training stage, it provides a **model registry** with **deployment functionality** to custom serving tools.\n",
        "\n",
        "It was created to :\n",
        "- Reduce the complexity in monitoring the experiments.\n",
        "- Ease the reproducibility of the¬†results.\n",
        "- Cater the need of a standardized mechanism to register and deploy models to production.\n",
        "\n",
        "**<h3> üéÇ Introduced in June 2018 by Databricks to offer </h3>**\n",
        "- **Open interface** : Any ML library, algorithm, cloud provider, or language may be used with MLflow.\n",
        "- **Open source** :¬†MLflow is an¬†open source project¬†that users and library developers can extend.\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1m0uXc3gZff1prgl_-DRfmg5whRwWboFJ\" height=\"\"/>\n",
        "</center>\n",
        "\n",
        "Reference blog to the stats - Click [here](https://www.databricks.com/blog/2018/06/05/introducing-mlflow-an-open-source-machine-learning-platform.html)!"
      ],
      "metadata": {
        "id": "WIU_pHsS5LDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß© The MLFlow Components:\n",
        "\n",
        "**Components that MLFlow offers to help you manage your workflow :**\n",
        "1. **MLflow Tracking -** Log parameters, metrics, and artifacts when running a machine learning code.\n",
        "2. **MLflow Projects**¬†- Package and reuse data science code.\n",
        "3. **MLflow Registry -** Manage the lifespan of ML Model.\n",
        "4. **MLflow Models**¬†- Package and deploy ML models.\n"
      ],
      "metadata": {
        "id": "HHfth5VnAYr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üî•MLflow Tracking Functionality\n"
      ],
      "metadata": {
        "id": "Ft1TaiLVCIzO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèÉ‚Äç‚ôÇÔ∏è& üß™ Understanding Runs & Experiments\n",
        "\n",
        "- The **experiment** unit in MLflow can be handled as a \"project\" or as a \"approach\".  \n",
        "- The term **run** merely refers to a run or execution of a code once.\n",
        "\n",
        "*More than one run might be associated with a single experiment.*\n",
        "\n",
        "Each run is an execution of your data science code which records the following:\n",
        "\n",
        "- **Source of execution**: Contains the hash of the commit if the code was pushed to GitHub and the original line of code that was utilized for the run.\n",
        "- **Artifacts**: Artifacts are output files recorded during a run.\n",
        "- **Parameters**: Parameters are stored in the key-value format.\n",
        "- **Metrics:** The evaluation metrics such as RMSE or ROC-AUC are recorded in a run as well."
      ],
      "metadata": {
        "id": "DSePjmf5F8Jz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úçÔ∏è How and where are the runs recorded?\n"
      ],
      "metadata": {
        "id": "uNOfQVFOju3Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Runs of MLflow can be stored locally in files, remotely on a tracking server, or in a database that is compatible with [SQLAlchemy](https://www.sqlalchemy.org/) - an open-source SQL toolkit and object-relational mapper for the Python programming language.*\n",
        "\n",
        "### Scenario 1: MLflow on localhost\n",
        "- A good first-time technique to get started.\n",
        "- MLflow will create a directory called **./mlruns** on your local system as soon as you import MLflow and log an artifact.\n",
        "- Limitations on collaboration because experiments or results can't be shared with a team.\n",
        "- Tracking UI - To visualize, search and compare runs, as well as download run artifacts or metadata for analysis in other tools by running the command `mlflow ui`.\n",
        "<center> <img src=\"https://drive.google.com/uc?id=182URyB-0ezmZCkQg-TKVrt-OmYbiyECM\" height=\"150%\"/>\n",
        "</center>\n",
        "\n",
        "The UI contains the following key features:\n",
        "\n",
        "- Experiment-based run listing and comparison (including run comparison across multiple experiments)\n",
        "- Searching for runs by parameter or metric value\n",
        "- Visualizing run metrics\n",
        "- Downloading run results"
      ],
      "metadata": {
        "id": "LZrJPCBjCIvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scenario 2: MLflow on localhost with SQLite\n",
        "\n",
        "The only difference between this process and the previous one is that we use a local database such as SQLite instead of storing runs to files."
      ],
      "metadata": {
        "id": "jhgxn4RSj4kk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\\\n",
        "\n",
        "### Scenario 3: MLflow on localhost with Tracking Server\n",
        "\n",
        "This scenario is again similar to the first scenario but here, you can setup a remote server using `mlflow server <args>` which will launch the tracking server at the default port 5000.\n",
        "\n"
      ],
      "metadata": {
        "id": "1IoeEu-Mj4bC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scenario 4: MLflow with remote Tracking Server, backend and artifact stores\n",
        "- The tracking server, backend store, and artifact store may all be located on different hosts in distributed architectures.\n",
        "- The MLflow client communicates with the tracking server through a sequence of REST requests in order to record all runs' MLflow entities.\n",
        "- The MLflow client interacts with the remote Tracking Server and artifact storage host such as AWS using the¬†boto client¬†libraries, and uploads the artifacts to the S3 bucket URI location.\n",
        "- This set up requires DevOps knowledge.\n",
        "\n",
        "\\\\\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1iqhhqw7yT4GjUlpV6IoYLLuy1BeVtDA0\" height=\"120%\"/>\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "DO6gTnOrj4X2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scenario 5: MLflow Tracking Server enabled with proxied artifact storage access\n",
        "\n",
        "\\\\\n",
        "\n",
        "*In this case, it is not necessary to grant end users direct path access to a remote object store (such as S3, ADL, GCS, or HDFS) for the management of artifact, nor is it necessary for an end user to provide access credentials.*\n",
        "\n",
        "\\\\\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=17ERqAUwx7OUcph3EjPUPL4OoyCwuhh2W\" height=\"120%\"/>\n",
        "</center>"
      ],
      "metadata": {
        "id": "pC2FkQoOj4V-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scenario 6: MLflow x DagsHub\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1kDoJcbYj_mebQ-6Dh6aPe-OE5LNSvqsR\" height=\"80%\"/>\n",
        "</center>\n",
        "\n",
        "- Going through all the above can be a bit of an hassle, even for people with DevOps background. To simplify the process, DagsHub decided to do the MLOps heavy lifting for you.\n",
        "\n",
        "- **DagsHub provides a free remote MLflow server with every repository.**\n",
        "\n",
        "- You can log experiments with MLflow to it, view its information under the¬†[experiment tab](https://dagshub.com/docs/feature_guide/discovering_experiments/), and manage your trained models from the full-fledged MLflow UI built into your DagsHub project.\n",
        "\n",
        "- When you create a repository on DagsHub, a remote MLflow server is automatically created and configured with the project. The repository's MLflow tracking server will be located at:\n",
        "\n",
        "  `https://dagshub.com/<DagsHub-user-name>/<repository-name>.mlflow`\n",
        "\n",
        "<center><h3>In the session today, we will use DagsHub integration with MLflow and log experiment to a remote server by running only 3 simple commands!</h3></center>"
      ],
      "metadata": {
        "id": "6ou-zNZOZp2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üíª Hands-on Experience using MLflow"
      ],
      "metadata": {
        "id": "xfujaAmeGeHH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To demo the MLflow functionality, I chose to use [Eryk Lewinson's awesome project](https://dagshub.com/eryk.lewinson/mario_vs_wario_v2), where he trains a neural network to classify images as containing Mario or Wario.\n",
        "\n",
        "To shorten the training time, I created a fork that trimmed the pipeline and uses a subset of the original data."
      ],
      "metadata": {
        "id": "7sBsk3NOGhJG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üë∑‚Äç‚ôÄÔ∏è Setup the project in Colab Runtime"
      ],
      "metadata": {
        "id": "6E4MGW5-FTE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DagsHub Configurations"
      ],
      "metadata": {
        "id": "wl78R8dPkRbD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First: fork the [base repository](https://dagshub.com/DagsHub/mario_vs_wario) to your account!**"
      ],
      "metadata": {
        "id": "Fg-Q1mtJF0bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dagshub --quiet"
      ],
      "metadata": {
        "id": "sj71-Rf80xAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Enter the username of your DagsHub account:\n",
        "DAGSHUB_USER_NAME = \"jinensetpal\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the email for your DagsHub account:\n",
        "DAGSHUB_EMAIL = \"jinens8@gmail.com\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the name of the forked repository!\n",
        "DAGSHUB_REPO = \"mario_vs_wario\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "ufslGlHVFYdc",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Generate an OAuth Token, for improved account security**"
      ],
      "metadata": {
        "id": "ugEEh97mPfCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dagshub\n",
        "import os\n",
        "\n",
        "DAGSHUB_TOKEN = dagshub.auth.get_token()"
      ],
      "metadata": {
        "id": "ilUliyVH0qym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚è¨ Clone the Project"
      ],
      "metadata": {
        "id": "MU7dNou0F9m_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configure Git**"
      ],
      "metadata": {
        "id": "QQsYUtDwGE1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email {DAGSHUB_EMAIL}\n",
        "!git config --global user.name {DAGSHUB_USER_NAME}"
      ],
      "metadata": {
        "id": "NkYJ39OXF7WK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clone the Repository**"
      ],
      "metadata": {
        "id": "Rd02jjRRGGFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://{DAGSHUB_USER_NAME}:{DAGSHUB_TOKEN}@dagshub.com/{DAGSHUB_USER_NAME}/{DAGSHUB_REPO}.git\n",
        "%cd {DAGSHUB_REPO}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og48wUBwGASF",
        "outputId": "684a06ad-7bdb-4e1f-fddf-7fec46e69785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'mario_vs_wario' already exists and is not an empty directory.\n",
            "/content/mario_vs_wario\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚è≥ Install MLflow\n",
        "MLflow is installed using pip.\n",
        "\n",
        "*Note*: MLflow has two variants, each with different support.\n",
        "\n",
        "* Install MLflow\n",
        "\n",
        "  `pip install mlflow`\n",
        "\n",
        "* Install a lightweight version of MLflow\n",
        "    \n",
        "    `pip install mlflow-skinny`"
      ],
      "metadata": {
        "id": "d5DIqa7EGqsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow --quiet"
      ],
      "metadata": {
        "id": "3grGRw_ZGn1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üêé Getting Started\n",
        "\n",
        "Let's dive into this project by exploring the [data pipeline](https://dagshub.com/DagsHub/mario_vs_wario)!\n",
        "\n",
        "From there, we can see that `src/train.py` is a pivotal script. Let's watch it work!"
      ],
      "metadata": {
        "id": "EPDpKEKKaYvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run src/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9zotxrG5xRB",
        "outputId": "c6a1c389-39a0-4126-af65-630d30dad17f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 107 images belonging to 2 classes.\n",
            "Found 25 images belonging to 2 classes.\n",
            "Found 45 images belonging to 2 classes.\n",
            "Training the model...\n",
            "Epoch 1/5\n",
            "4/4 [==============================] - 4s 696ms/step - loss: 0.7212 - accuracy: 0.5140 - val_loss: 0.6850 - val_accuracy: 0.6000\n",
            "Epoch 2/5\n",
            "4/4 [==============================] - 3s 665ms/step - loss: 0.6938 - accuracy: 0.5701 - val_loss: 0.6691 - val_accuracy: 0.6000\n",
            "Epoch 3/5\n",
            "4/4 [==============================] - 3s 789ms/step - loss: 0.6924 - accuracy: 0.5234 - val_loss: 0.6630 - val_accuracy: 0.6000\n",
            "Epoch 4/5\n",
            "4/4 [==============================] - 3s 593ms/step - loss: 0.6753 - accuracy: 0.6636 - val_loss: 0.6411 - val_accuracy: 0.6000\n",
            "Epoch 5/5\n",
            "4/4 [==============================] - 3s 656ms/step - loss: 0.6512 - accuracy: 0.6822 - val_loss: 0.5937 - val_accuracy: 0.8800\n",
            "Training completed.\n",
            "Evaluating the model...\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.6585 - accuracy: 0.6444\n",
            "Evaluating completed.\n",
            "Saving the model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!du -sh data"
      ],
      "metadata": {
        "id": "HFuhDoUQ3-1-",
        "outputId": "66aa5437-0cf1-4281-a319-64049d03081e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0M\tdata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "etlSznFa3-u5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Log Experiments Locally"
      ],
      "metadata": {
        "id": "-anNKKYaGxuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Import MLflow\n"
      ],
      "metadata": {
        "id": "o1vQ19POG30n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "# We will import mlflow to the train.py where we will later log our runs.\n",
        "import mlflow\n",
        "```"
      ],
      "metadata": {
        "id": "T6QZf0cpOE4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Create an Experiment & Get the Experiment ID\n",
        "\n",
        "There are two ways to create an experiment with MLflow :\n",
        "1. **CLI** (Command-Line Interface)\n",
        "\n",
        "  MLflow supports various functionalities from the [CLI](https://www.mlflow.org/docs/latest/cli.html). You can use the CLI to run projects, launch the Tracking UI, create and list experiments, and more.\n",
        "\n",
        "  To create a new experiment use:\n",
        "  ```\n",
        "  mlflow experiments create --experiment-name <experiment_name>\n",
        "  ```\n",
        "\n",
        "2. **Python API**\n",
        "    ```\n",
        "    mlflow.create_experiment(name)\n",
        "    ```\n",
        "\n",
        "**Note**: The process of creating an experiment should be separated from the project pipeline or main code because we don't need to create a new one every time we run it."
      ],
      "metadata": {
        "id": "rzE99ovrHF1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "\n",
        "import mlflow\n",
        "\n",
        "def get_experiment_id(name):\n",
        "    exp = mlflow.get_experiment_by_name(name)\n",
        "    if exp is None:\n",
        "      exp_id = mlflow.create_experiment(name)\n",
        "      return exp_id\n",
        "    return exp.experiment_id\n",
        "\n",
        "print(get_experiment_id(\"mario_wario\"))\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "TUrFUDJZY7m-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run src/get_or_create_mlflow_experiment.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXbaGC5CGtP4",
        "outputId": "4518d365-6a92-4d9e-aa71-6d0613e9a89e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Allocate the run to the Experiment\n",
        "\n",
        "We start an MLflow run with the command :\n",
        "```\n",
        "with mlflow.start_run(experiment_id=<experiment id>):\n",
        "```\n",
        "We will copy paste this to our train.py with the Experiment ID that we obtained from our last code execution.\n",
        "\n",
        "***Note:*** The code that followes this line needs to be indented to the `with` block"
      ],
      "metadata": {
        "id": "rUeAdt1TI_5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Log Information  \n",
        "\n",
        "We will start by importing MLflow into our notebook or a .py file. Then we can start using the manual logging commands to log parameters, metrics, artifacts, and general using the following methods:\n",
        "\n",
        "* **Parameters**:\n",
        "  * [Single parameter](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_param): mlflow.log_param(*key, value*)\n",
        "  * [Multiple parameters](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_params): mlflow.log_params(*dict*)\n",
        "* **Metrics:**\n",
        "  * [Single metric](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_metric): mlflow.log_metric(*key, value*)\n",
        "  * [Multiple metrics](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_metrics): mlflow.log_metrics(*dict*)\n",
        "* **Artifacts**:\n",
        "  * [Single artifact](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_artifact): mlflow.log_artifact(*local_path: str*)\n",
        "* **Text**:\n",
        "  * [Text](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_text): mlflow.log_text(*string*,*local_path: str*)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "***Note***: MLflow has additional logging capabilities, to read more about them please refer to the [MLflow Tracking docs](https://www.mlflow.org/docs/latest/python_api/mlflow.html#module-mlflow)\n",
        "\n",
        "\n",
        "***Note***: All the mlflow code in this section should be under the `with mlflow.start_run(experiment_id=<experiment id>):` line from the previous section.\n",
        "\n",
        "```\n",
        "# Single parameter\n",
        "mlflow.log_param(\"img_size\", IMG_SIZE)\n",
        "\n",
        "# Multiple parameters\n",
        "mlflow.log_params({\n",
        "    \"img_size\": IMG_SIZE,\n",
        "    \"learning_rate\": LR,\n",
        "    \"epochs\": EPOCHS\n",
        "})\n",
        "\n",
        "# Single metric\n",
        "mlflow.log_metric(\"test_set_loss\", test_loss, step=1)\n",
        "\n",
        "\n",
        "# Multiple metrics\n",
        "mlflow.log_metrics(\n",
        "    {\n",
        "        \"test_set_loss\": test_loss,\n",
        "        \"test_set_accuracy\": test_accuracy,\n",
        "    }\n",
        ")\n",
        "\n",
        "mlflow.log_artifact(MODELS_DIR)\n",
        "\n",
        "mlflow.log_text(\"Here you can add general inforamtion about the run\",\"run_info.txt\")\n",
        "```"
      ],
      "metadata": {
        "id": "4q_aHvrnIlv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Time to see the magic! üîç"
      ],
      "metadata": {
        "id": "Fuui_bvgKmaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout HEAD -- src/train.py"
      ],
      "metadata": {
        "id": "7CwOvl5myQF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ftxNUfLkzZdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run src/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4F11GuVIWIq",
        "outputId": "eb40c219-5cac-479c-b74f-ad2edd082199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 107 images belonging to 2 classes.\n",
            "Found 25 images belonging to 2 classes.\n",
            "Found 45 images belonging to 2 classes.\n",
            "Training the model...\n",
            "Epoch 1/5\n",
            "4/4 [==============================] - 6s 1s/step - loss: 0.7126 - accuracy: 0.4953 - val_loss: 0.6884 - val_accuracy: 0.6000\n",
            "Epoch 2/5\n",
            "4/4 [==============================] - 3s 869ms/step - loss: 0.7119 - accuracy: 0.6075 - val_loss: 0.6824 - val_accuracy: 0.6000\n",
            "Epoch 3/5\n",
            "4/4 [==============================] - 3s 604ms/step - loss: 0.6991 - accuracy: 0.5140 - val_loss: 0.6824 - val_accuracy: 0.6000\n",
            "Epoch 4/5\n",
            "4/4 [==============================] - 3s 640ms/step - loss: 0.6791 - accuracy: 0.5888 - val_loss: 0.6762 - val_accuracy: 0.6000\n",
            "Epoch 5/5\n",
            "4/4 [==============================] - 3s 663ms/step - loss: 0.6766 - accuracy: 0.5888 - val_loss: 0.6688 - val_accuracy: 0.6000\n",
            "Training completed.\n",
            "Evaluating the model...\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.7401 - accuracy: 0.3778\n",
            "Evaluating completed.\n",
            "Saving the model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explore the Files\n",
        "\n",
        "The information will be logged to the `mlruns` directory.\n",
        "\n",
        "In our example the directory will have the following structure:\n",
        "\n",
        "```\n",
        "mlruns\n",
        "‚îî‚îÄ‚îÄ <experiment ID>\n",
        "    ‚îú‚îÄ‚îÄ <Run Hash>\n",
        "    ‚îÇ   ‚îú‚îÄ‚îÄ artifacts\n",
        "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models\n",
        "    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ run_info.txt\n",
        "    ‚îÇ   ‚îú‚îÄ‚îÄ meta.yaml\n",
        "    ‚îÇ   ‚îú‚îÄ‚îÄ metrics\n",
        "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_set_accuracy\n",
        "    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_set_loss\n",
        "    ‚îÇ   ‚îú‚îÄ‚îÄ params\n",
        "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ epochs\n",
        "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ img_size\n",
        "    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ learning_rate\n",
        "    ‚îÇ   ‚îî‚îÄ‚îÄ tags\n",
        "    ‚îÇ       ‚îú‚îÄ‚îÄ mlflow.source.git.commit\n",
        "    ‚îÇ       ‚îú‚îÄ‚îÄ mlflow.source.name\n",
        "    ‚îÇ       ‚îú‚îÄ‚îÄ mlflow.source.type\n",
        "    ‚îÇ       ‚îî‚îÄ‚îÄ mlflow.user\n",
        "    ‚îî‚îÄ‚îÄ meta.yaml\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "O_cxp1fcK-7H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚òÅÔ∏è Log Experiments to a Remote Tracking Server\n",
        "\n",
        "To avoide the long process of setting up a remote server,  we will use DagsHub integration with MLflow.\n",
        "\n",
        "When you create a repository on DagsHub, a remote MLflow server is automatically created and configured with the project. The repository's MLflow tracking server will be located at:\n",
        "\n",
        "`https://dagshub.com/<DagsHub-user-name>/<repository-name>.mlflow`\n",
        "\n",
        "To set the remote server with you machine you need to:\n",
        "1. **Set DagsHub as the remote URI -**\n",
        "  * `mlflow.set_tracking_uri(\"https://dagshub.com/<DagsHub-user-name>/<repository-name>.mlflow\")`\n",
        "2. **Set-up your credentials as OS variables**:\n",
        "  * `export MLFLOW_TRACKING_USERNAME=<DagsHub-user-name/token>`\n",
        "  * `export MLFLOW_TRACKING_PASSWORD=<password>`\n",
        "\n",
        "**Congratulations**, you are ready to start logging experiments."
      ],
      "metadata": {
        "id": "OrYrefNqLLzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Set up environment variables"
      ],
      "metadata": {
        "id": "R7KtpI0tNyNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['MLFLOW_TRACKING_USERNAME'] = DAGSHUB_USER_NAME\n",
        "os.environ['MLFLOW_TRACKING_PASSWORD'] = DAGSHUB_TOKEN\n",
        "\n",
        "os.environ['MLFLOW_TRACKING_URI'] = f'https://dagshub.com/{DAGSHUB_USER_NAME}/{DAGSHUB_REPO}.mlflow'"
      ],
      "metadata": {
        "id": "CSznfaCFNmfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Create a new experiment on the remote server\n",
        "\n",
        "We will modify get_or_create_mlflow_experiment.py, and set the tracking URI\n",
        "\n",
        "```\n",
        "import mlflow\n",
        "import os\n",
        "\n",
        "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
        "\n",
        "def get_experiment_id(name):\n",
        "    exp = mlflow.get_experiment_by_name(name)\n",
        "    if exp is None:\n",
        "      exp_id = mlflow.create_experiment(name)\n",
        "      return exp_id\n",
        "    return exp.experiment_id\n",
        "\n",
        "print(get_experiment_id(\"mario_wario\"))\n",
        "```"
      ],
      "metadata": {
        "id": "hwYgCo93NYoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run src/get_or_create_mlflow_experiment.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19MUlYxLpKGx",
        "outputId": "5b29499b-2b20-47a2-92f4-f7f5d7b725e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Modify the train.py script\n",
        "\n",
        "We will modify train.py, and set the tracking URI and set the new experiment id\n"
      ],
      "metadata": {
        "id": "9rcECrp3hrLe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "# To be added to the top of train.py\n",
        "\n",
        "import os\n",
        "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
        "# Recommended way:\n",
        "# mlflow.set_tracking_uri(\"https://dagshub.com/{user name}/{repo name}.mlflow\")\n",
        "\n",
        "# To be added in lime 93\n",
        "with mlflow.start_run(experiment_id=<experiment id>):\n",
        "```"
      ],
      "metadata": {
        "id": "X5Qe0SHgN50N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Logging & visualizing the runs on remote server"
      ],
      "metadata": {
        "id": "8SBptQ5-zK-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "\n",
        "display(IPython.display.IFrame(f\"https://dagshub.com/{DAGSHUB_USER_NAME}/{DAGSHUB_REPO}/experiments/#/\",'100%',600))"
      ],
      "metadata": {
        "id": "UtbLjJKSzubh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Re-running the code to see the logs"
      ],
      "metadata": {
        "id": "jbEkavuGzmzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run src/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpx81y7-N9i3",
        "outputId": "bd419a07-b272-4cfa-b09e-1339ec31d7e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 107 images belonging to 2 classes.\n",
            "Found 25 images belonging to 2 classes.\n",
            "Found 45 images belonging to 2 classes.\n",
            "Training the model...\n",
            "Epoch 1/5\n",
            "4/4 [==============================] - 6s 911ms/step - loss: 0.7559 - accuracy: 0.5514 - val_loss: 0.6958 - val_accuracy: 0.6000\n",
            "Epoch 2/5\n",
            "4/4 [==============================] - 3s 644ms/step - loss: 0.6674 - accuracy: 0.5981 - val_loss: 0.6790 - val_accuracy: 0.6000\n",
            "Epoch 3/5\n",
            "4/4 [==============================] - 3s 615ms/step - loss: 0.6910 - accuracy: 0.5514 - val_loss: 0.6835 - val_accuracy: 0.6000\n",
            "Epoch 4/5\n",
            "4/4 [==============================] - 3s 765ms/step - loss: 0.6875 - accuracy: 0.5794 - val_loss: 0.6767 - val_accuracy: 0.6000\n",
            "Epoch 5/5\n",
            "4/4 [==============================] - 3s 589ms/step - loss: 0.6700 - accuracy: 0.5701 - val_loss: 0.6621 - val_accuracy: 0.6000\n",
            "Training completed.\n",
            "Evaluating the model...\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.6798 - accuracy: 0.5556\n",
            "Evaluating completed.\n",
            "Saving the model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöñ Logging all your information to a run with an Autologger!\n"
      ],
      "metadata": {
        "id": "d4Y9YshflFLn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "If you are a forgetful human logger like me who always forgets to log something to the TensorBoard or the outputs, you will probably appreciate this feature the most!\n",
        "\n",
        "Automatic logging allows you to log metrics, parameters, and models without the need for explicit log statements. MLFlow Autologger supports the following libraries :\n",
        "\n",
        "1. Scikit-learn\n",
        "2. TensorFlow and Keras\n",
        "3. Gluon\n",
        "4. XGBoost\n",
        "5. LightGBM\n",
        "6. Statsmodels\n",
        "7. Spark\n",
        "8. Fastai\n",
        "9. Pytorch\n",
        "\n",
        "While you can use `mlflow.autolog()` to enable logging for all the above supported libraries, alternatively you can use library-specific autolog calls for each library, let‚Äôs use the specific autolog call for tensorflow :\n"
      ],
      "metadata": {
        "id": "eV5rLMFT0Jx5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add ```mlflow.tensorflow.autolog()``` right above the call ```with mlflow.start_run():``` and re-run your code to see the logged metrics and artifacts with the autologger."
      ],
      "metadata": {
        "id": "km10q-b90Rid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run src/train.py"
      ],
      "metadata": {
        "id": "HUW257oH2w35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afec6fd2-d9fd-4745-aa90-8723cc6172f9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 107 images belonging to 2 classes.\n",
            "Found 25 images belonging to 2 classes.\n",
            "Found 45 images belonging to 2 classes.\n",
            "Training the model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023/07/19 15:46:51 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.preprocessing.image.DirectoryIterator'>. Dataset logging skipped.\n",
            "2023/07/19 15:46:51 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.preprocessing.image.DirectoryIterator'>. Dataset logging skipped.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "4/4 [==============================] - 5s 829ms/step - loss: 0.6643 - accuracy: 0.6168 - val_loss: 0.6789 - val_accuracy: 0.6000\n",
            "Epoch 2/5\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.7549 - accuracy: 0.5514 - val_loss: 0.6803 - val_accuracy: 0.8400\n",
            "Epoch 3/5\n",
            "4/4 [==============================] - 3s 656ms/step - loss: 0.6997 - accuracy: 0.5140 - val_loss: 0.6800 - val_accuracy: 0.7600\n",
            "Epoch 4/5\n",
            "4/4 [==============================] - 3s 677ms/step - loss: 0.6843 - accuracy: 0.5607 - val_loss: 0.6755 - val_accuracy: 0.5600\n",
            "Epoch 5/5\n",
            "4/4 [==============================] - 3s 641ms/step - loss: 0.6769 - accuracy: 0.6355 - val_loss: 0.6666 - val_accuracy: 0.5600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023/07/19 15:47:17 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: '>=' not supported between instances of 'slice' and 'int'\n",
            "2023/07/19 15:47:17 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
            "2023/07/19 15:47:29 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpdlr5bbiy/model, flavor: tensorflow), fall back to return ['tensorflow==2.12.0']. Set logging level to DEBUG to see the full traceback.\n",
            "2023/07/19 15:47:29 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed.\n",
            "Evaluating the model...\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.6712 - accuracy: 0.5778\n",
            "Evaluating completed.\n",
            "Saving the model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Saving the Project**"
      ],
      "metadata": {
        "id": "ljsreg3IZxTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -a -m \"added mlflow logging\"\n",
        "!git push origin main"
      ],
      "metadata": {
        "id": "lGw_sVoXZ23E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed735aa9-e4cc-4a24-8947-24d7611da23d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 243c62e] added mlflow logging\n",
            " 2 files changed, 24 insertions(+), 13 deletions(-)\n",
            "Enumerating objects: 9, done.\n",
            "Counting objects: 100% (9/9), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (5/5), done.\n",
            "Writing objects: 100% (5/5), 762 bytes | 762.00 KiB/s, done.\n",
            "Total 5 (delta 4), reused 0 (delta 0)\n",
            "To https://dagshub.com/jinensetpal/mario_vs_wario.git\n",
            "   399eec1..243c62e  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üéâ **Congratulations!**\n",
        "\n",
        "You can now integrate MLFlow's experiment tracking to all your projects!"
      ],
      "metadata": {
        "id": "tbEtnQqq9YDV"
      }
    }
  ]
}